# Web Scraping and Text Analysis
A Python project demonstrating practical data mining techniques including web scraping, text preprocessing, natural language processing, and exploratory data analysis.

This project was developed as part of my undergraduate‑level work in Data Science and Statistics. 
It highlights my ability to collect real‑world unstructured data, clean and transform text, and extract meaningful insights through computational methods.

For demonstration purposes, this analysis uses publicly available faculty biographies from a randomly selected university department with a well‑structured online directory. The goal of this project is to showcase technical skills in data mining and Natural Language Processing, not to draw substantive conclusions about the institution or its faculty.

### This notebook contains the full analysis of the Georia Tech Directory, including the use of skills such as:
- Web Scraping
- Uses requests and BeautifulSoup to collect faculty profile data from the Georgia Tech School of International Affairs
- Extracts names, profile links, and biography text for downstream analysis
- Text Cleaning & Preprocessing
- Implementing tokenization, stopword removal, punctuation stripping, and number filtering
- Building custom cleaning functions to standardize and prepare text for Natural Language Processing tasks
- Exploratory Text Analysis
- Computes word frequencies and identifies the most common terms across faculty biographies
- Constructs a term-document frequency matrix to analyze patterns across profiles
- Word Associations
- Examining co-occurrence patterns for key terms such as international, research, and university
- Highlighting thematic relationships within the faculty’s academic focus areas
- Visualization
- Producing bar charts, word clouds, and sentiment plots using seaborn, matplotlib, and plotly
- Visual summaries helping illustrate dominant themes and tone
- Sentiment Analysis
- Applying VADER to evaluate positive, negative, and neutral sentiment across sentences
- Including line‑level and sentence‑level sentiment breakdowns

---

## Technologies Used
- Python
- Web Scraping (requests, BeautifulSoup)
- Natural Language Processing (nltk, vaderSentiment)
- Data Manipulation (pandas, numpy)
- Visualization (matplotlib, seaborn, plotly, WordCloud)

---

## Purpose of This Project
This project is intended to showcase:
- My ability to collect and analyze unstructured text data
- Strong understanding of data cleaning and Natural Language Process workflows
- Clear, organized, and well-documented analytical code
- Experience applying statistical and computational techniques to real‑world datasets

Note: The dataset was chosen solely because it provided a clean, consistent directory suitable for demonstrating scraping and analysis techniques. The results are not meant to represent any formal evaluation of the institution or its faculty; the focus is on methodology and technical execution.

---

Author
Olivia Rueschhoff  
M.S. in Mathematics | B.S. in Mathematics (Data Science & Statistics)
Minor: Computer Science (Algorithms & Data Structures)
